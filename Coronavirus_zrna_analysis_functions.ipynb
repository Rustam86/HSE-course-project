{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rustam86/HSE-course-project/blob/main/coronavirus_zrna_analysis_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaFvxsZS1153"
      },
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oefzFcrj1156"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import tempfile\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from Bio import Entrez, SeqIO\n",
        "from matplotlib.lines import Line2D\n",
        "from scipy.cluster.hierarchy import dendrogram, fcluster, linkage\n",
        "from scipy import ndimage, stats\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from transformers import BertForTokenClassification, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcVaKRpN1157"
      },
      "outputs": [],
      "source": [
        "def seq2kmer(seq: str, k: int) -> List[str]:\n",
        "    \"\"\"\n",
        "    Converts a sequence into a list of k-mers.\n",
        "\n",
        "    Parameters:\n",
        "    seq (str): The sequence to convert.\n",
        "    k (int): The length of the k-mers.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of k-mers.\n",
        "    \"\"\"\n",
        "    return [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
        "\n",
        "\n",
        "def split_seq(seq: str, length: int = 512, pad: int = 16) -> List[str]:\n",
        "    \"\"\"\n",
        "    Splits a sequence into smaller pieces.\n",
        "\n",
        "    Parameters:\n",
        "    seq (str): The sequence to split.\n",
        "    length (int): The length of the pieces.\n",
        "    pad (int): The overlap between the pieces.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of sequence pieces.\n",
        "    \"\"\"\n",
        "    return [seq[st:min(st+512, len(seq))] for st in range(0, len(seq), length-pad)]\n",
        "\n",
        "\n",
        "def stitch_np_seq(np_seqs: List[np.ndarray], pad: int = 16) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Stitches together the predictions for each piece of the sequence.\n",
        "\n",
        "    Parameters:\n",
        "    np_seqs (List[np.ndarray]): A list of numpy arrays containing the predictions.\n",
        "    pad (int): The overlap between the pieces.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: A numpy array containing the stitched predictions.\n",
        "    \"\"\"\n",
        "    res = np.array([])\n",
        "    for seq in np_seqs:\n",
        "        res = np.concatenate([res[:-pad], seq])\n",
        "    return res\n",
        "\n",
        "from transformers import BertForTokenClassification, BertTokenizer\n",
        "\n",
        "def zdnabert(sequence: str, model: BertForTokenClassification, tokenizer: BertTokenizer, model_confidence_threshold: float = 0.2, minimum_sequence_length: int = 10) -> dict:\n",
        "    \"\"\"\n",
        "    Predicts Z-DNA regions in a given sequence using a trained model.\n",
        "\n",
        "    Parameters:\n",
        "        sequence (str): The DNA sequence to analyze.\n",
        "        model (BertForTokenClassification): The trained model.\n",
        "        tokenizer (BertTokenizer): The tokenizer.\n",
        "        model_confidence_threshold (float): The threshold for the model's confidence.\n",
        "        minimum_sequence_length (int): The minimum length of a sequence to consider.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where the keys are the sequence names and the values are lists of tuples representing the predicted Z-DNA regions.\n",
        "    \"\"\"\n",
        "    result_dict = {}\n",
        "\n",
        "    # Convert sequence to k-mers\n",
        "    kmer_seq = seq2kmer(sequence.upper(), 6)\n",
        "    # Split the sequence into smaller pieces\n",
        "    seq_pieces = split_seq(kmer_seq)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Iterate over each sequence piece and perform Z-DNA prediction\n",
        "        preds = [torch.softmax(\n",
        "            model(\n",
        "                torch.LongTensor(\n",
        "                    tokenizer.encode(' '.join(seq_piece), add_special_tokens=False)).unsqueeze(0)\n",
        "            ).squeeze()[:, 1].cpu().numpy()) for seq_piece in seq_pieces]\n",
        "        result_dict['sequence'] = stitch_np_seq(preds)\n",
        "\n",
        "    labeled_regions = {}\n",
        "    for seq_name, predictions in result_dict.items():\n",
        "        # Label connected regions above the confidence threshold\n",
        "        labeled, max_label = scipy.ndimage.label(predictions > model_confidence_threshold)\n",
        "        # Extract regions longer than the minimum sequence length\n",
        "        labeled_regions[seq_name] = [(candidate[0], candidate[-1]) for label in range(1, max_label + 1) for candidate in [np.where(labeled == label)[0]] if\n",
        "                                     candidate.shape[0] > minimum_sequence_length]\n",
        "\n",
        "    return labeled_regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpZE_RPl1158"
      },
      "outputs": [],
      "source": [
        "def run_zhunt(sequence: str, zhunt_path: str, window_size: int = 6, min_size: int = 3, max_size: int = 6) -> List[Tuple[int, int]]:\n",
        "    \"\"\"\n",
        "    Run the ZHunt program to predict Z-DNA forming regions in a DNA sequence.\n",
        "\n",
        "    Parameters:\n",
        "    sequence (str): The DNA sequence to analyze.\n",
        "    zhunt_path (str): The path to the ZHunt executable.\n",
        "    window_size (int): The window size for the ZHunt program. Default is 6.\n",
        "    min_size (int): The minimum size for the ZHunt program. Default is 3.\n",
        "    max_size (int): The maximum size for the ZHunt program. Default is 6.\n",
        "\n",
        "    Returns:\n",
        "    List[Tuple[int, int]]: A list of tuples representing the start and end positions of the predicted Z-DNA forming regions.\n",
        "    \"\"\"\n",
        "    # Ensure the sequence only contains valid DNA bases\n",
        "    assert set(sequence).issubset({\"A\", \"C\", \"G\", \"T\", \"N\"}), \"Invalid DNA sequence\"\n",
        "\n",
        "    # Create a temporary file\n",
        "    file_descriptor, temp_file_path = tempfile.mkstemp()\n",
        "    os.close(file_descriptor)\n",
        "\n",
        "    try:\n",
        "        # Write the sequence to the temporary file\n",
        "        with open(temp_file_path, 'w') as temp_file:\n",
        "            temp_file.write(sequence)\n",
        "\n",
        "        # Run the ZHunt program\n",
        "        subprocess.run(\n",
        "            [zhunt_path, str(window_size), str(min_size), str(max_size), temp_file_path],\n",
        "            check=True, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL,\n",
        "            input=sequence, encoding='ascii'\n",
        "        )\n",
        "\n",
        "        # Read the ZHunt output into a DataFrame\n",
        "        with open(temp_file_path + \".Z-SCORE\", 'r') as zhunt_output:\n",
        "            output_data = pd.read_csv(zhunt_output,\n",
        "                             names=['Start', 'End', 'nu-1', 'nu-2', 'nu-3',\n",
        "                                    'ZH-Score', 'Sequence', 'Conformation'],\n",
        "                             skiprows=1, sep='\\s+')\n",
        "\n",
        "        # Filter the DataFrame to only include rows with a ZH-Score greater than 500\n",
        "        filtered_data = output_data[output_data['ZH-Score'] > 500]\n",
        "\n",
        "        # Return a list of tuples representing the start and end positions of the predicted Z-DNA forming regions\n",
        "        return list(zip(filtered_data['Start'], filtered_data['End']))\n",
        "\n",
        "    except Exception as error:\n",
        "        print(f\"An error occurred while running ZHunt: {error}\")\n",
        "\n",
        "    finally:\n",
        "        # Clean up the temporary files\n",
        "        os.remove(temp_file_path)\n",
        "        os.remove(temp_file_path + \".Z-SCORE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSaFxCYo1159"
      },
      "outputs": [],
      "source": [
        "def parse_prediction_files(file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parse Z-DNABERT and ZHunt output files.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): The path to the file to parse.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing the parsed data.\n",
        "    \"\"\"\n",
        "    # Initialize an empty dictionary to store the parsed data\n",
        "    parsed_data = {}\n",
        "    current_key = ''\n",
        "\n",
        "    # Open the file and read it line by line\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Remove leading and trailing whitespace from the line\n",
        "            trimmed_line = line.strip()\n",
        "\n",
        "            # Skip lines ending with '.fas' or starting with \"100%|\"\n",
        "            if trimmed_line.endswith('.fas') or trimmed_line.startswith(\"100%|\"):\n",
        "                continue\n",
        "\n",
        "            # If the line doesn't start with '  ' or '   ', it's a key\n",
        "            if not trimmed_line.startswith(('  ', '   ')):\n",
        "                current_key = trimmed_line\n",
        "                parsed_data[current_key] = []\n",
        "            # If the line starts with '   ', it's a value\n",
        "            elif trimmed_line.startswith('   '):\n",
        "                # Convert the line into a list of floats and append it to the current key\n",
        "                values = [float(i) for i in trimmed_line.split()]\n",
        "                parsed_data[current_key].append(values)\n",
        "\n",
        "        # If a key has only one value, append a default value\n",
        "        for key, value in parsed_data.items():\n",
        "            if len(value) == 1:\n",
        "                value.append([0, 0, False])\n",
        "\n",
        "        # Remove the empty key if it exists\n",
        "        parsed_data.pop('', None)\n",
        "\n",
        "    # Return the parsed data\n",
        "    return parsed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxkaDByN115-"
      },
      "outputs": [],
      "source": [
        "def compute_jaccard_index(set_intervals1: List[Tuple[int, int]], set_intervals2: List[Tuple[int, int]]) -> float:\n",
        "    \"\"\"\n",
        "    This function computes the Jaccard index between two sets of intervals.\n",
        "\n",
        "    Parameters:\n",
        "    set_intervals1, set_intervals2 (list of tuples): The intervals to be compared.\n",
        "\n",
        "    Returns:\n",
        "    jaccard_index (float): The Jaccard index between the two sets of intervals.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute the intersection of the two sets of intervals\n",
        "    intersection_size = sum(min(interval2[1], interval1[1]) - max(interval2[0], interval1[0])\n",
        "                            for interval1 in set_intervals1\n",
        "                            for interval2 in set_intervals2\n",
        "                            if interval1[1] > interval2[0] and interval2[1] > interval1[0])\n",
        "\n",
        "    # Compute the size of intervals in set_intervals1 that do not overlap with set_intervals2\n",
        "    non_overlap_size1 = sum(interval1[1] - interval1[0]\n",
        "                            for interval1 in set_intervals1\n",
        "                            if not any(interval1[1] > interval2[0] and interval2[1] > interval1[0]\n",
        "                                       for interval2 in set_intervals2))\n",
        "\n",
        "    # Compute the size of intervals in set_intervals2 that do not overlap with set_intervals1\n",
        "    non_overlap_size2 = sum(interval2[1] - interval2[0]\n",
        "                            for interval2 in set_intervals2\n",
        "                            if not any(interval2[1] > interval1[0] and interval1[1] > interval2[0]\n",
        "                                       for interval1 in set_intervals1))\n",
        "\n",
        "    # Compute the size of the union of the two sets of intervals\n",
        "    union_size = intersection_size + non_overlap_size1 + non_overlap_size2\n",
        "\n",
        "    # Compute the Jaccard index\n",
        "    if union_size:\n",
        "        jaccard_index = intersection_size / union_size\n",
        "    else:\n",
        "        jaccard_index = 1\n",
        "\n",
        "    return jaccard_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZNIWtHK115-"
      },
      "outputs": [],
      "source": [
        "def create_clustered_dataframe(zrna_intervals_file_path: str, virus_name: str, dataframe_subset: pd.DataFrame) -> Tuple[pd.DataFrame, np.ndarray, int]:\n",
        "    \"\"\"\n",
        "    This function creates a clustered dataframe based on Jaccard indices of intervals.\n",
        "\n",
        "    Parameters:\n",
        "    zrna_intervals_file_path (str): The file containing Z-RNA interval data.\n",
        "    virus_name (str): The name of the virus.\n",
        "    dataframe_subset (pd.DataFrame): The subset of the dataframe to be clustered.\n",
        "\n",
        "    Returns:\n",
        "    clustered_dataframe (pd.DataFrame): The clustered dataframe.\n",
        "    row_linkage_matrix (np.ndarray): The hierarchical clustering encoded as a linkage matrix.\n",
        "    optimal_color_threshold (int): The optimal color threshold for the clusters.\n",
        "    \"\"\"\n",
        "\n",
        "    # Parse the intervals file\n",
        "    intervals_dict = parse_prediction_files(zrna_intervals_file_path)\n",
        "    sequence_ids = list(intervals_dict.keys())\n",
        "\n",
        "    # Check if there are enough sequences\n",
        "    if len(sequence_ids) < 5:\n",
        "        return 'Less than 5 sequences'\n",
        "\n",
        "    # Copy the dataframe subset\n",
        "    dataframe_subset_copy = dataframe_subset.copy()\n",
        "\n",
        "    # Compute the Jaccard index matrix\n",
        "    intervals_list = list(intervals_dict.items())\n",
        "    interval_count = len(intervals_list)\n",
        "    sequence_labels = [intervals_list[i][0] for i in range(interval_count)]\n",
        "    jaccard_index_matrix = [[compute_jaccard_index(intervals_list[i][1], intervals_list[j][1]) for j in range(interval_count)] for i in range(interval_count)]\n",
        "    jaccard_dataframe = pd.DataFrame(jaccard_index_matrix, index=sequence_labels, columns=sequence_labels)\n",
        "\n",
        "    # Perform hierarchical clustering on rows and columns\n",
        "    row_linkage_matrix = linkage(jaccard_dataframe.values, method='average', metric='euclidean')\n",
        "    column_linkage_matrix = linkage(jaccard_dataframe.values.T, method='average', metric='euclidean')\n",
        "\n",
        "    # Reorder the dataframe based on the clustering\n",
        "    row_dendrogram = dendrogram(row_linkage_matrix, no_plot=True)\n",
        "    column_dendrogram = dendrogram(column_linkage_matrix, no_plot=True)\n",
        "    clustered_dataframe = jaccard_dataframe.iloc[row_dendrogram['leaves'], column_dendrogram['leaves']]\n",
        "\n",
        "    # Find the optimal color threshold for the clusters\n",
        "    max_cluster_count = -1\n",
        "    optimal_color_threshold = -1\n",
        "    for color_threshold in range(2, 7):\n",
        "        cluster_index = fcluster(row_linkage_matrix, t=color_threshold, criterion='distance')\n",
        "        cluster_count = len(set(cluster_index))\n",
        "        if cluster_count <= 10 and cluster_count > max_cluster_count:\n",
        "            max_cluster_count = cluster_count\n",
        "            optimal_color_threshold = color_threshold\n",
        "\n",
        "    return clustered_dataframe, row_linkage_matrix, optimal_color_threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHZ8M_WI115-"
      },
      "outputs": [],
      "source": [
        "def plot_heatmap_with_dendrogram(clustered_dataframe: pd.DataFrame, row_linkage_matrix: np.ndarray, color_threshold: float,\n",
        "                                 title: str = 'Heat map with dendrogram', figsize: Tuple[int, int] = (10, 10),\n",
        "                                 save_figure: bool = False, file_name: str = 'results', close_figure: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    This function plots a heatmap with a dendrogram.\n",
        "\n",
        "    Parameters:\n",
        "    clustered_dataframe (pd.DataFrame): The clustered dataframe to be plotted.\n",
        "    row_linkage_matrix (np.ndarray): The hierarchical clustering encoded as a linkage matrix.\n",
        "    color_threshold (float): The color threshold for the dendrogram.\n",
        "    title (str): The title of the plot.\n",
        "    figsize (tuple): The size of the figure.\n",
        "    save_figure (bool): Whether to save the figure.\n",
        "    file_name (str): The name of the file to save the figure as.\n",
        "    close_figure (bool): Whether to close the figure after plotting.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a figure to contain the plot elements\n",
        "    figure = plt.figure(figsize=figsize)\n",
        "\n",
        "    # Create a gridspec to handle the layout\n",
        "    grid_spec = figure.add_gridspec(2, 2, width_ratios=[0.05, 1], height_ratios=[0.2, 1], wspace=0.02, hspace=0.02)\n",
        "\n",
        "    # Add dendrogram on top\n",
        "    dendrogram_axis = figure.add_subplot(grid_spec[0, 1])\n",
        "    with plt.rc_context({'lines.linewidth': 0.5}):\n",
        "        dendrogram = dendrogram(row_linkage_matrix, ax=dendrogram_axis, orientation='top', color_threshold=color_threshold)\n",
        "    dendrogram_axis.axis('off')\n",
        "\n",
        "    # Assign each data point to a cluster\n",
        "    clusters = fcluster(row_linkage_matrix, color_threshold, criterion='distance')\n",
        "\n",
        "    # Create a color map\n",
        "    color_map = {\n",
        "        1: \"#1f77b4\",\n",
        "        2: \"#ff7f0e\",\n",
        "        3: \"#2ca02c\",\n",
        "        4: \"#d62728\",\n",
        "        5: \"#9467bd\",\n",
        "        6: \"#8c564b\",\n",
        "        7: \"#e377c2\",\n",
        "        8: \"#7f7f7f\",\n",
        "        9: \"#bcbd22\",\n",
        "        10: \"#17becf\",\n",
        "        11: \"#ff00ff\",\n",
        "        12: \"#00ffff\",\n",
        "        13: \"#ffff00\",\n",
        "        14: \"#800080\",\n",
        "        15: \"#008080\",\n",
        "        16: \"#008000\",\n",
        "        17: \"#800000\",\n",
        "        18: \"#000080\",\n",
        "        19: \"#808080\",\n",
        "        20: \"#ff0000\"\n",
        "    }\n",
        "\n",
        "    # Change the color of each line to match the cluster colors\n",
        "    for i, d, c in zip(dendrogram['icoord'], dendrogram['dcoord'], clusters):\n",
        "        for j in range(4):\n",
        "            x = 0.5 * sum(i[j:j+2])\n",
        "            y = d[j]\n",
        "            dendrogram_axis.plot(x, y, color=color_map[c])\n",
        "\n",
        "    # Add heatmap\n",
        "    heatmap_axis = figure.add_subplot(grid_spec[1, 1])\n",
        "    sns.heatmap(clustered_dataframe, annot=False, ax=heatmap_axis, cbar=False, xticklabels=False, yticklabels=False)\n",
        "\n",
        "    # Add title to the entire figure\n",
        "    figure.suptitle(title, fontsize=10, y=0.91)\n",
        "\n",
        "    plt.tick_params(labelsize=5)\n",
        "    if save_figure:\n",
        "        plt.savefig(f\"{file_name}_heatmap.png\")\n",
        "        plt.savefig(f\"{file_name}_heatmap.pdf\")\n",
        "    if close_figure:\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd5JrTck115_"
      },
      "outputs": [],
      "source": [
        "def plot_time_length_regression(df: pd.DataFrame, row_linkage: np.ndarray, color_threshold: float,\n",
        "                                title: str = 'Time and ZNA length regression',\n",
        "                                remove_outliers: Tuple[bool, int] = (False, 3),\n",
        "                                figsize: Tuple[int, int] = (10, 5), point_size: int = 3,\n",
        "                                save: bool = False, normalize: bool = False, file_name: str = 'results',\n",
        "                                legend_loc: str = 'best', off: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    This function plots a time-length regression.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The dataframe to be plotted.\n",
        "    row_linkage (np.ndarray): The hierarchical clustering encoded as a linkage matrix.\n",
        "    color_threshold (float): The color threshold for the dendrogram.\n",
        "    title (str): The title of the plot.\n",
        "    remove_outliers (Tuple[bool, int]): A tuple indicating whether to remove outliers and the z-score threshold for outlier removal.\n",
        "    figsize (Tuple[int, int]): The size of the figure.\n",
        "    point_size (int): The size of the points in the scatter plot.\n",
        "    save (bool): Whether to save the figure as a PNG.\n",
        "    normalize (bool): Whether to normalize the data.\n",
        "    file_name (str): The name of the file to save the figure as.\n",
        "    legend_loc (str): The location of the legend.\n",
        "    off (bool): Whether to close the figure after plotting.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    # Copy the dataframe\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Normalize the data if specified\n",
        "    if normalize:\n",
        "        df_copy['Normalized_Length'] = df_copy['Intervals total length'] / df_copy.loc[df_copy['Accession'].isin(df_copy['Accession']), 'Sequence Length']\n",
        "        length_column = 'Normalized_Length'\n",
        "    else:\n",
        "        length_column = 'Intervals total length'\n",
        "\n",
        "    # Assign each data point to a cluster\n",
        "    df_copy['Clusters'] = fcluster(row_linkage, t=color_threshold, criterion='distance')\n",
        "\n",
        "    # Convert the collection date to datetime and ordinal\n",
        "    df_copy['Collection_Date'] = pd.to_datetime(df_copy['Collection Date'], errors='coerce')\n",
        "    df_copy = df_copy.dropna(subset=['Collection_Date'])\n",
        "    df_copy['Date_Ordinal'] = df_copy['Collection_Date'].apply(lambda x: x.toordinal())\n",
        "\n",
        "    # Remove outliers if specified\n",
        "    if remove_outliers[0]:\n",
        "        z_scores = df_copy[['Date_Ordinal', 'Intervals total length']].apply(lambda x: (x - x.mean()) / x.std())\n",
        "        df_copy = df_copy[(np.abs(z_scores['Date_Ordinal']) <= remove_outliers[1]) & (np.abs(z_scores['Intervals total length']) <= remove_outliers[1])]\n",
        "\n",
        "    # Create a color map\n",
        "    color_map = {\n",
        "        1: \"#1f77b4\",\n",
        "        2: \"#ff7f0e\",\n",
        "        3: \"#2ca02c\",\n",
        "        4: \"#d62728\",\n",
        "        5: \"#9467bd\",\n",
        "        6: \"#8c564b\",\n",
        "        7: \"#e377c2\",\n",
        "        8: \"#7f7f7f\",\n",
        "        9: \"#bcbd22\",\n",
        "        10: \"#17becf\",\n",
        "        11: \"#ff00ff\",\n",
        "        12: \"#00ffff\",\n",
        "        13: \"#ffff00\",\n",
        "        14: \"#800080\",\n",
        "        15: \"#008080\",\n",
        "        16: \"#008000\",\n",
        "        17: \"#800000\",\n",
        "        18: \"#000080\",\n",
        "        19: \"#808080\",\n",
        "        20: \"#ff0000\"\n",
        "    }\n",
        "\n",
        "    # Fit a linear regression model\n",
        "    X = df_copy[['Date_Ordinal']]\n",
        "    y = df_copy[length_column]\n",
        "    regression_model = LinearRegression()\n",
        "    regression_model.fit(X, y)\n",
        "    y_pred = regression_model.predict(X)\n",
        "\n",
        "    # Create the figure\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Plot the data points for each cluster\n",
        "    for cluster in set(df_copy['Clusters']):\n",
        "        plt.scatter(df_copy[df_copy['Clusters'] == cluster]['Collection_Date'],\n",
        "                    df_copy[df_copy['Clusters'] == cluster][length_column],\n",
        "                    color=color_map[cluster], label=f\"Cluster: {cluster}\", s=point_size)\n",
        "\n",
        "    # Plot the regression line\n",
        "    plt.plot(df_copy['Collection_Date'], y_pred, color='red', label='Regression Line')\n",
        "\n",
        "    # Get the slope and intercept of the regression line\n",
        "    slope = regression_model.coef_[0]\n",
        "    intercept = regression_model.intercept_\n",
        "\n",
        "    # Create a list of legend elements\n",
        "    legend_elements = [Line2D([0], [0], marker='o', color='w', label=f\"Cluster: {cluster}\", markerfacecolor=color, markersize=10)\n",
        "                       for cluster, color in color_map.items()]\n",
        "    legend_elements.append(Line2D([0], [0], color='red', lw=2, label='Regression Line'))\n",
        "    legend_elements.append(Line2D([0], [0], marker='None', color='w', label=f\"Slope = {slope:.2f}\\nIntercept = {intercept:.2f}\"))\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.legend(handles=legend_elements, loc=legend_loc)\n",
        "    plt.grid(visible=True, which='major', axis='both', linestyle='-')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Collection Date')\n",
        "    plt.ylabel('Z-RNA Regions Length')\n",
        "\n",
        "    # Save the figure if specified\n",
        "    if save:\n",
        "        plt.savefig(f\"{file_name}_heatmap.png\")\n",
        "        plt.savefig(f\"{file_name}_heatmap.pdf\")\n",
        "\n",
        "    # Close the figure if specified\n",
        "    if off:\n",
        "        plt.close()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stvb2S2S115_"
      },
      "outputs": [],
      "source": [
        "def create_genbank_info_df(ids: List[str], intervals: Dict[str, List[List[int]]]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function fetches information for each GenBank ID from the NCBI database and stores it in a pandas DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - ids (List[str]): A list of GenBank IDs.\n",
        "    - intervals (Dict[str, List[List[int]]]): A dictionary of intervals.\n",
        "\n",
        "    Returns:\n",
        "    - df (pd.DataFrame): A pandas DataFrame containing the fetched information.\n",
        "    \"\"\"\n",
        "\n",
        "    # Entrez email (required for accessing NCBI databases)\n",
        "    Entrez.email = 'rustam_msu@mail.ru'\n",
        "\n",
        "    def fetch_genbank_info(genbank_id: str) -> SeqIO.SeqRecord:\n",
        "        \"\"\"\n",
        "        Fetches information for a given GenBank ID from the NCBI database.\n",
        "\n",
        "        Parameters:\n",
        "        - genbank_id (str): GenBank ID.\n",
        "\n",
        "        Returns:\n",
        "        - record (SeqIO.SeqRecord): SeqRecord containing the fetched information.\n",
        "        \"\"\"\n",
        "        handle = Entrez.efetch(db='nuccore', id=genbank_id, rettype='gb', retmode='text')\n",
        "        record = SeqIO.read(handle, 'genbank')\n",
        "        handle.close()\n",
        "        return record\n",
        "\n",
        "    def get_length_value(intervals: Dict[str, List[List[int]]], genbank_id: str) -> int:\n",
        "        \"\"\"\n",
        "        Calculates the total length of intervals for a given GenBank ID.\n",
        "\n",
        "        Parameters:\n",
        "        - intervals (Dict[str, List[List[int]]]): A dictionary of intervals.\n",
        "        - genbank_id (str): GenBank ID.\n",
        "\n",
        "        Returns:\n",
        "        - length (int): Total length of intervals.\n",
        "        \"\"\"\n",
        "        return sum(interval[1] - interval[0] for interval in intervals[genbank_id])\n",
        "\n",
        "    def get_mean_length_value(intervals: Dict[str, List[List[int]]], genbank_id: str) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the mean length of intervals for a given GenBank ID.\n",
        "\n",
        "        Parameters:\n",
        "        - intervals (Dict[str, List[List[int]]]): A dictionary of intervals.\n",
        "        - genbank_id (str): GenBank ID.\n",
        "\n",
        "        Returns:\n",
        "        - mean_length (float): Mean length of intervals.\n",
        "        \"\"\"\n",
        "        lengths = [interval[1] - interval[0] for interval in intervals[genbank_id]]\n",
        "        return sum(lengths) / len(lengths) if lengths else 0\n",
        "\n",
        "    # Create an empty dataframe to store the information\n",
        "    df = pd.DataFrame(columns=['GenBank ID', 'Accession', 'Description', 'Collection Date', 'Geographic Location',\n",
        "                               'Sequence Length', 'Host', 'Intervals Total Length', 'Intervals Mean Length'])\n",
        "\n",
        "    # Fetch information for each GenBank ID\n",
        "    for genbank_id in ids:\n",
        "        record = fetch_genbank_info(genbank_id)\n",
        "\n",
        "        # Extract relevant information\n",
        "        accession = record.id\n",
        "        description = record.description\n",
        "\n",
        "        # Extract source features\n",
        "        collection_date = record.features[0].qualifiers.get('collection_date', '')\n",
        "        if collection_date == '':\n",
        "            collection_date = record.annotations.get('date', '')\n",
        "        # Remove square brackets from collection_date\n",
        "        if isinstance(collection_date, list):\n",
        "            collection_date = collection_date[0] if collection_date else ''\n",
        "        geographic_location = record.features[0].qualifiers.get('country')\n",
        "\n",
        "        # Extract host information\n",
        "        features = record.features\n",
        "        host = ''\n",
        "        for feature in features:\n",
        "            if feature.type == 'source' and 'host' in feature.qualifiers:\n",
        "                host = feature.qualifiers['host'][0]\n",
        "                break\n",
        "\n",
        "        # Append the information to the dataframe\n",
        "        df = df.append({'GenBank ID': genbank_id,\n",
        "                        'Accession': accession,\n",
        "                        'Description': description,\n",
        "                        'Collection Date': collection_date,\n",
        "                        'Geographic Location': geographic_location,\n",
        "                        'Sequence Length': len(record.seq),\n",
        "                        'Host': host,\n",
        "                        'Intervals Total Length': get_length_value(intervals, genbank_id),\n",
        "                        'Intervals Mean Length': get_mean_length_value(intervals, genbank_id)\n",
        "                        }, ignore_index=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5XRquEp116A"
      },
      "outputs": [],
      "source": [
        "def pango_to_who(pango_lineage: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts Pango lineage of SARS-CoV-2 virus to WHO label.\n",
        "\n",
        "    Args:\n",
        "        pango_lineage (str): A string representing the Pango lineage of the virus.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the WHO label.\n",
        "    \"\"\"\n",
        "    pango_lineage = pango_lineage.upper()\n",
        "\n",
        "    pango_to_who_map = {\n",
        "        \"B.1.1.7\": \"Alpha\",\n",
        "        \"Q\": \"Alpha\",\n",
        "        \"B.1.351\": \"Beta\",\n",
        "        \"P.1\": \"Gamma\",\n",
        "        \"B.1.617.2\": \"Delta\",\n",
        "        \"B.1.617.1\": \"Kappa\",\n",
        "        \"B.1.617.3\": \"Kappa\",\n",
        "        \"B.1.427\": \"Epsilon\",\n",
        "        \"B.1.429\": \"Epsilon\",\n",
        "        \"B.1.525\": \"Eta\",\n",
        "        \"B.1.526\": \"Iota\",\n",
        "        \"C.37\": \"Lambda\",\n",
        "        \"B.1.621\": \"Mu\",\n",
        "        \"B.1.621.1\": \"Mu\",\n",
        "        \"BA.1\": \"Omicron\",\n",
        "        \"BA.2\": \"Omicron\",\n",
        "        \"BA.4\": \"Omicron\",\n",
        "        \"BA.5\": \"Omicron\",\n",
        "        \"BA.2.12.1\": \"Omicron\",\n",
        "        \"BA.2.75\": \"Omicron\",\n",
        "        \"BQ.1\": \"Omicron\",\n",
        "        \"XBB.1.5\": \"Omicron\",\n",
        "        \"XBB.1.16\": \"Omicron\",\n",
        "        \"P.2\": \"Zeta\"\n",
        "    }\n",
        "\n",
        "    for pango, who in pango_to_who_map.items():\n",
        "        if pango_lineage.startswith(pango):\n",
        "            return who\n",
        "\n",
        "    return \"Unknown\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H94tcJaX116A"
      },
      "outputs": [],
      "source": [
        "def plot_zna_regions(regions: dict, data: List[Tuple[str, int, int]], colors: List[str], figsize: Tuple[int, int] = (30, 15)):\n",
        "    \"\"\"\n",
        "    Plots the ZNA regions along with additional regions.\n",
        "\n",
        "    Args:\n",
        "        regions (dict): A dictionary of additional regions.\n",
        "        data (List[Tuple[str, int, int]]): A list of tuples representing the ZNA regions.\n",
        "        colors (List[str]): A list of colors corresponding to each ZNA region.\n",
        "        figsize (Tuple[int, int]): The figure size. Defaults to (30, 15).\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    genes, starts, ends = zip(*data)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        ax.hlines(y=0, xmin=starts[i], xmax=ends[i], linewidth=10, color=colors[i])\n",
        "\n",
        "    # Set the x-axis limits to the extent of the genome\n",
        "    lim = max(ends) + 50\n",
        "    ax.set_xlim(0, lim)\n",
        "\n",
        "    # Remove the y-axis ticks and labels\n",
        "    ax.yaxis.set_visible(False)\n",
        "\n",
        "    # Add a grid\n",
        "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Remove the top and right spines\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "\n",
        "    # Add padding to the bottom spine\n",
        "    ax.spines['bottom'].set_linewidth(1.5)\n",
        "    ax.spines['bottom'].set_position(('outward', 10))\n",
        "\n",
        "    # Format the x-axis ticks and labels with gene names\n",
        "    xticks = []\n",
        "    xlabels = []\n",
        "    for i in range(len(data)):\n",
        "        xticks.append((starts[i] + ends[i]) / 2)\n",
        "        xlabels.append(data[i][0])\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_xticklabels(xlabels, fontsize=10)\n",
        "\n",
        "    # Rotate the x-axis labels for readability\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    # Add a legend\n",
        "    patches = [plt.Rectangle((0, 0), 1, 1, color=colors[i]) for i in range(len(data))]\n",
        "    ax.legend(patches, genes, loc='upper center', bbox_to_anchor=(0.5, -0.25), ncol=5, fontsize=10)\n",
        "\n",
        "    # Adjust the spacing between subplots to prevent overlap\n",
        "    plt.subplots_adjust(bottom=0.35)\n",
        "\n",
        "    # Plot additional regions\n",
        "    counter = 1\n",
        "    for key, value in regions.items():\n",
        "        additional_data = [(region[0], region[1]) for region in value[1:]]\n",
        "        additional_starts, additional_ends = zip(*additional_data)\n",
        "        for i in range(len(additional_data)):\n",
        "            ax.hlines(y=counter, xmin=additional_starts[i], xmax=additional_ends[i], linewidth=5)\n",
        "        counter += 0.25\n",
        "\n",
        "    # Add a title and axis labels\n",
        "    title = list(regions.values())[0][0]\n",
        "    ax.set_title(title, fontsize=16)\n",
        "    ax.set_xlabel('Position (nucleotides)', fontsize=12)\n",
        "\n",
        "    # Add the number of strains\n",
        "    n_strains = len(regions)\n",
        "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "    ax.text(0.05, 0.95, f\"Number of strains: {n_strains}\", transform=ax.transAxes, fontsize=18,\n",
        "            verticalalignment='top', bbox=props)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbuQ_xcN116B"
      },
      "outputs": [],
      "source": [
        "def zna_banch_prediction(file: str, function, function_params) -> None:\n",
        "    \"\"\"\n",
        "    Perform a given function on sequences in a file and write the results to a new file.\n",
        "\n",
        "    Args:\n",
        "        file (str): The path to the input file.\n",
        "        function (callable): The function to perform on the sequences.\n",
        "        function_params (dict): The parameters to pass to the function.\n",
        "    \"\"\"\n",
        "    with open(file, 'r') as input_file, open(f'{function.__name__}_{file}', \"w\") as output_file:\n",
        "        file_name = input_file.name.split('/')[-1]\n",
        "        output_file.write(f\"{file_name}\\n\")\n",
        "\n",
        "        for sequence_record in SeqIO.parse(input_file, format='fasta'):\n",
        "            sequence_id = sequence_record.id\n",
        "            output_file.write(f\"{sequence_id}\\n\")\n",
        "            sequence = str(sequence_record.seq)\n",
        "            regions = function(sequence, **function_params)\n",
        "            output_file.write(\"  start     end\\n\")\n",
        "\n",
        "            for region in regions:\n",
        "                output_file.write(f\"   {region[0]}   {region[1]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0Zh1GQS116B"
      },
      "outputs": [],
      "source": [
        "def filter_arrays(arrays):\n",
        "    \"\"\"\n",
        "    Filters arrays by removing those that contain NaN values or have a length of zero.\n",
        "\n",
        "    Parameters:\n",
        "    - arrays (list): A list of arrays.\n",
        "\n",
        "    Returns:\n",
        "    - filtered_arrays (list): A list of filtered arrays.\n",
        "    \"\"\"\n",
        "    filtered_arrays = []\n",
        "    for array in arrays:\n",
        "        if np.isnan(array).any() or len(array) == 0:\n",
        "            continue\n",
        "        filtered_arrays.append(array)\n",
        "    return filtered_arrays\n",
        "\n",
        "\n",
        "def draw_boxplot_species(\n",
        "        data_subset: pd.DataFrame,\n",
        "        category_label: str = 'name',\n",
        "        value_label: str = 'Intervals total length',\n",
        "        plot_title: str = '',\n",
        "        figure_size: Tuple[int, int] = (15, 6),\n",
        "        text_position: Tuple[float, float] = (0.02, 0.02),\n",
        "        legend_location: str = 'best') -> None:\n",
        "    \"\"\"\n",
        "    Draws a boxplot for certain categories.\n",
        "\n",
        "    Parameters:\n",
        "    data_subset (pd.DataFrame): The subset of the data to be plotted.\n",
        "    category_label (str): The name of the column representing the category.\n",
        "    value_label (str): The name of the column representing the values.\n",
        "    plot_title (str): The title of the plot.\n",
        "    figure_size (Tuple[int, int]): The size of the figure.\n",
        "    text_position (Tuple[float, float]): The position of the text inside the plot.\n",
        "    legend_location (str): The location of the legend.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # The unique categories\n",
        "    categories = list(data_subset[category_label].unique())\n",
        "\n",
        "    # Mapping English letters to Greek letters\n",
        "    greek_dict = {\n",
        "        'a': r'$\\alpha$', 'b': r'$\\beta$', 'g': r'$\\gamma$', 'd': r'$\\delta$', 'e': r'$\\epsilon$',\n",
        "        'z': r'$\\zeta$', 'h': r'$\\eta$', 'th': r'$\\theta$', 'i': r'$\\iota$', 'k': r'$\\kappa$',\n",
        "        'l': r'$\\lambda$', 'm': r'$\\mu$', 'n': r'$\\nu$', 'x': r'$\\xi$', 'p': r'$\\pi$', 'r': r'$\\rho$',\n",
        "        's': r'$\\sigma$', 't': r'$\\tau$', 'ph': r'$\\phi$', 'ch': r'$\\chi$', 'ps': r'$\\psi$', 'o': r'$\\omega$'\n",
        "    }\n",
        "\n",
        "    # Specify the species groups\n",
        "    species_groups = sorted([\n",
        "        'Cats/Dogs/Swine', 'Bats', 'Fish', 'Birds', 'Whales',\n",
        "        'Human/Cattle', 'Rodentia', 'Swine', 'Eulipotyphla', 'Human', 'Mink'\n",
        "    ])\n",
        "\n",
        "    # Filter the DataFrame to only include rows where 'species' is in species_groups\n",
        "    data_subset = data_subset[data_subset['species'].isin(species_groups)]\n",
        "\n",
        "    # Sort dataframe by species\n",
        "    data_subset = data_subset.sort_values(by='species')\n",
        "\n",
        "    # Store the 'Intervals total length' for each category\n",
        "    category_values = []\n",
        "    for category in categories:\n",
        "        values = data_subset[data_subset[category_label] == category][value_label].values\n",
        "        if not np.isnan(values).any():\n",
        "            category_values.append(values)\n",
        "\n",
        "    # Assuming that this function exists\n",
        "    category_values = filter_arrays(category_values)\n",
        "\n",
        "    # Perform the ANOVA\n",
        "    f_value, p_value = stats.f_oneway(*category_values)\n",
        "\n",
        "    # Create a figure and axis for the plot\n",
        "    fig, ax = plt.subplots(figsize=figure_size)\n",
        "\n",
        "    # Create the boxplot with seaborn\n",
        "    box_plot = sns.boxplot(\n",
        "        x=category_label,\n",
        "        y=value_label,\n",
        "        hue='species',\n",
        "        data=data_subset,\n",
        "        dodge=False\n",
        "    )\n",
        "\n",
        "    # Add a title and labels\n",
        "    ax.set_title(plot_title)\n",
        "    ax.set_xlabel('Species')\n",
        "    ax.set_ylabel(f'Z-RNA {value_label}')\n",
        "\n",
        "    # Get color palette\n",
        "    palette = sns.color_palette(\"husl\", 11)\n",
        "\n",
        "    # Create a mapping of labels to species\n",
        "    label_to_species = data_subset.groupby(category_label)['species'].agg(pd.Series.mode).to_dict()\n",
        "\n",
        "    # Create a mapping of species to colors\n",
        "    species_to_colors = dict(zip(species_groups, palette))\n",
        "\n",
        "    # Mapping taxa to colors\n",
        "    taxa_to_colors = {\n",
        "        'alphapironavirus': '#FF6B6B',  # Light Red\n",
        "        'alphacoronavirus': '#4ECDC4',  # Turquoise\n",
        "        'betacoronavirus': '#556270',   # Dark Grayish Blue\n",
        "        'deltacoronavirus': '#C7F464',  # Light Yellow Green\n",
        "        'gammacoronavirus': '#FFA577'   # Light Orange\n",
        "    }\n",
        "\n",
        "    # Apply the colors to the labels based on the most common species for that label\n",
        "    for i, label_text in enumerate(ax.get_xticklabels()):\n",
        "        species = label_to_species[label_text.get_text()]\n",
        "        color = species_to_colors[species]\n",
        "        label_text.set_color(color)\n",
        "\n",
        "        # Extract the corresponding 'taxa' value for the label\n",
        "        taxa = data_subset[data_subset[category_label] == label_text.get_text()]['taxa'].unique()[0]\n",
        "        # Convert first letter to Greek equivalent\n",
        "        taxa = taxa.lower()\n",
        "        taxa_greek = greek_dict.get(taxa[:taxa.find('coronavirus')], taxa[0])\n",
        "\n",
        "        # Update y position to below y=0 and set color based on taxa\n",
        "        ax.text(\n",
        "            (i + 0.5) / len(categories), 0.01, taxa_greek,\n",
        "            horizontalalignment='center', size='small', color='black',\n",
        "            weight='semibold', transform=ax.transAxes,\n",
        "            bbox=dict(facecolor=taxa_to_colors[taxa], alpha=0.5, boxstyle='round,pad=0.2')\n",
        "        )\n",
        "\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=7, fontweight='bold')\n",
        "\n",
        "    # Set the legend title\n",
        "    ax.legend(title='Host species', loc=legend_location)\n",
        "\n",
        "    # Add the F-value, p-value, and test name inside the plot\n",
        "    anova_text = f'ANOVA Test\\nF-value: {f_value:.2f}\\nP-value: {p_value:.4f}'\n",
        "    ax.text(\n",
        "        *text_position, anova_text, transform=ax.transAxes, fontsize=10,\n",
        "        verticalalignment='bottom', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkq45kZO116B"
      },
      "outputs": [],
      "source": [
        "def draw_simple_barplot(data: Dict, title: str = 'Count of variants',\n",
        "                 figsize: tuple = (15, 6), palette: str = \"husl\",\n",
        "                 desat: float = 0.6) -> None:\n",
        "    \"\"\"Draws a bar plot using seaborn and matplotlib.\n",
        "\n",
        "    Args:\n",
        "        data: A dictionary containing the data to be plotted. The keys represent the categories (x-values), and the\n",
        "              values represent the counts (y-values).\n",
        "        title: A string representing the title of the plot. Default is 'Count of variants'.\n",
        "        figsize: A tuple representing the size of the figure. Default is (15, 6).\n",
        "        palette: A string representing the color palette to use. Default is 'husl'.\n",
        "        desat: A float representing the desaturation level of the colors. Default is 0.6.\n",
        "    \"\"\"\n",
        "    # Define color palette\n",
        "    colors = sns.color_palette(palette, len(data), desat=desat)\n",
        "\n",
        "    # Create a new figure\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Plot the data\n",
        "    bars = plt.bar(data.keys(), data.values(), color=colors, edgecolor='black')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Variant')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title(title)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Data\n",
        "data_6M = {\n",
        "    'Alpha': 545082,\n",
        "    'Beta': 7606,\n",
        "    'Gamma': 27169,\n",
        "    'Delta': 80825,\n",
        "    'Epsilon': 41707,\n",
        "    'Eta': 2683,\n",
        "    'Iota': 33131,\n",
        "    'Kappa': 563,\n",
        "    'Lambda': 1328,\n",
        "    'Mu': 5190,\n",
        "    'Omicron': 2738343,\n",
        "    'Zeta': 1309,\n",
        "    'Unknown': 3060362\n",
        "}\n",
        "\n",
        "data_4k = {\n",
        "    'Alpha': 304,\n",
        "    'Beta': 5,\n",
        "    'Gamma': 33,\n",
        "    'Delta': 17,\n",
        "    'Epsilon': 64,\n",
        "    'Eta': 4,\n",
        "    'Iota': 67,\n",
        "    'Kappa': 1,\n",
        "    'Lambda': 1,\n",
        "    'Mu': 1,\n",
        "    'Omicron': 2728,\n",
        "    'Zeta': 1,\n",
        "    'Unknown': 1097\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Oftm5co116C"
      },
      "outputs": [],
      "source": [
        "def draw_boxplot_who(\n",
        "        df_subset: pd.DataFrame,\n",
        "        label: str = 'WHO label',\n",
        "        values: str = 'Intervals total length',\n",
        "        title: str = '',\n",
        "        figsize: Tuple[int, int] = (15, 6),\n",
        "        pos: Tuple[float, float] = (0.02, 0.02)) -> None:\n",
        "    \"\"\"\n",
        "    Draws a boxplot for a given DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    df_subset (pd.DataFrame): The subset of the data to be plotted.\n",
        "    label (str): The name of the column representing the category.\n",
        "    values (str): The name of the column representing the values.\n",
        "    title (str): The title of the plot.\n",
        "    figsize (Tuple[int, int]): The size of the figure.\n",
        "    pos (Tuple[float, float]): The position of the text inside the plot.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Pangolin values\n",
        "    pangolin_values = ['Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon', 'Eta', 'Iota', 'Kappa', 'Lambda', 'Mu', 'Omicron', 'Unknown', 'Zeta']\n",
        "\n",
        "    # Create an empty list to store the 'Intervals total length' for each 'Pangolin' value\n",
        "    data = []\n",
        "\n",
        "    # For each 'Pangolin' value, append the 'Intervals total length' to the data list\n",
        "    for pangolin in pangolin_values:\n",
        "        data.append(df_subset[df_subset[label] == pangolin][values].values)\n",
        "\n",
        "    # Perform the ANOVA\n",
        "    f_value, p_value = stats.f_oneway(*data)\n",
        "\n",
        "    # Create a figure and axis for the plot\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Create the boxplot with seaborn\n",
        "    sns.boxplot(x=label, y=values, data=df_subset, order=pangolin_values, ax=ax)\n",
        "\n",
        "    # Add a title and labels\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(label)\n",
        "    ax.set_ylabel(f'Z-RNA {values}')\n",
        "\n",
        "    # Add the F-value, p-value, and test name inside the plot\n",
        "    anova_text = f'ANOVA Test\\nF-value: {f_value:.2f}\\nP-value: {p_value:.2f}'\n",
        "    ax.text(\n",
        "        *pos, anova_text, transform=ax.transAxes, fontsize=10,\n",
        "        verticalalignment='bottom', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
